{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"import argparse\nimport os\nimport sys\n\nimport cv2\nimport editdistance\nimport numpy as np\nimport tensorflow as tf\n\nfrom DataLoader import Batch, DataLoader, FilePaths\nfrom SamplePreprocessor import preprocessor as preprocess\nfrom SamplePreprocessor import wer\nfrom Model import DecoderType, Model\n# from SpellChecker import correct_sentence\n\nCUDA_VISIBLE_DEVICES = 0\n\ndef train(model, loader):\n\t\"train NN\"\n\tepoch = 0 # number of training epochs since start\n\tbestCharErrorRate = float('inf') # best valdiation character error rate\n\tnoImprovementSince = 0 # number of epochs no improvement of character error rate occured\n\tearlyStopping = 5 # stop training after this number of epochs without improvement\n\tbatchNum = 0\n\twhile True:\n\t\tepoch += 1\n\t\tprint('Epoch:', epoch)\n\n\t\t# train\n\t\tprint('Train NN')\n\t\tloader.trainSet()\n\t\twhile loader.hasNext():\n\t\t\tbatchNum += 1\n\t\t\titerInfo = loader.getIteratorInfo()\n\t\t\tbatch = loader.getNext()\n\t\t\tloss = model.trainBatch(batch, batchNum)\n\t\t\tprint('Batch:', iterInfo[0],'/', iterInfo[1], 'Loss:', loss)\n\n\t\t# validate\n\t\tcharErrorRate = validate(model, loader)\n\t\t\n\t\t# if best validation accuracy so far, save model parameters\n\t\tif charErrorRate < bestCharErrorRate:\n\t\t\tprint('Character error rate improved, save model')\n\t\t\tbestCharErrorRate = charErrorRate\n\t\t\tnoImprovementSince = 0\n\t\t\tmodel.save()\n\t\t\topen(FilePaths.fnAccuracy, 'w').write('Validation character error rate of saved model: %f%%' % (charErrorRate*100.0))\n\t\telse:\n\t\t\tprint('Character error rate not improved')\n\t\t\tnoImprovementSince += 1\n\n\t\t# stop training if no more improvement in the last x epochs\n\t\tif noImprovementSince >= earlyStopping:\n\t\t\tprint('No more improvement since %d epochs. Training stopped.' % earlyStopping)\n\t\t\tbreak\n\n\ndef validate(model, loader):\n\t\"validate NN\"\n\tprint('Validate NN')\n\tloader.validationSet()\n\tnumCharErr = 0\n\tnumCharTotal = 0\n\tnumWordOK = 0\n\tnumWordTotal = 0\n\twhile loader.hasNext():\n\t\titerInfo = loader.getIteratorInfo()\n\t\tprint('Batch:', iterInfo[0],'/', iterInfo[1])\n\t\tbatch = loader.getNext()\n\t\t(recognized, _) = model.inferBatch(batch)\n\t\t\n\t\tprint('Ground truth -> Recognized')\t\n\t\tfor i in range(len(recognized)):\n\t\t\tnumWordOK += 1 if batch.gtTexts[i] == recognized[i] else 0\n\t\t\tnumWordTotal += 1\n\t\t\tdist = editdistance.eval(recognized[i], batch.gtTexts[i])\n\t\t\tnumCharErr += dist\n\t\t\tnumCharTotal += len(batch.gtTexts[i])\n\t\t\tprint('[OK]' if dist==0 else '[ERR:%d]' % dist,'\"' + batch.gtTexts[i] + '\"', '->', '\"' + recognized[i] + '\"')\n\t\n\t# print validation result\n\tcharErrorRate = numCharErr / numCharTotal\n\twordAccuracy = numWordOK / numWordTotal\n\tprint('Character error rate: %f%%. Word accuracy: %f%%.' % (charErrorRate*100.0, wordAccuracy*100.0))\n\treturn charErrorRate\n\n\ndef infer(model, fnImg):\n\t\"recognize text in image provided by file path\"\n\timg = preprocess(cv2.imread(fnImg, cv2.IMREAD_GRAYSCALE), Model.imgSize)\n\tbatch = Batch(None, [img])\n\t(recognized, probability) = model.inferBatch(batch, True)\n\tprint('Recognized:', '\"' + recognized[0] + '\"')\n\tprint('Probability:', probability[0])\n\n\ndef main():\n\t\"main function\"\n\t# optional command line args\n\tparser = argparse.ArgumentParser()\n\tparser.add_argument('--train', help='train the NN', action='store_true')\n\tparser.add_argument('--validate', help='validate the NN', action='store_true')\n\tparser.add_argument('--beamsearch', help='use beam search instead of best path decoding', action='store_true')\n\tparser.add_argument('--wordbeamsearch', help='use word beam search instead of best path decoding', action='store_true')\n\tparser.add_argument('--dump', help='dump output of NN to CSV file(s)', action='store_true')\n\n\targs = parser.parse_args()\n\n\tdecoderType = DecoderType.BestPath\n\tif args.beamsearch:\n\t\tdecoderType = DecoderType.BeamSearch\n\telif args.wordbeamsearch:\n\t\tdecoderType = DecoderType.WordBeamSearch\n\n\t# train or validate on IAM dataset\t\n\tif args.train or args.validate:\n\t\t# load training data, create TF model\n\t\tloader = DataLoader(FilePaths.fnTrain, Model.batchSize, Model.imgSize, Model.maxTextLen)\n\n\t\t# save characters of model for inference mode\n\t\topen(FilePaths.fnCharList, 'w').write(str().join(loader.charList))\n\t\t\n\t\t# save words contained in dataset into file\n\t\topen(FilePaths.fnCorpus, 'w').write(str(' ').join(loader.trainWords + loader.validationWords))\n\n\t\t# execute training or validation\n\t\tif args.train:\n\t\t\tmodel = Model(loader.charList, decoderType)\n\t\t\ttrain(model, loader)\n\t\telif args.validate:\n\t\t\tmodel = Model(loader.charList, decoderType, mustRestore=True)\n\t\t\tvalidate(model, loader)\n\n\t# infer text on test image\n\telse:\n\t\tprint(open(FilePaths.fnAccuracy).read())\n\t\tmodel = Model(open(FilePaths.fnCharList).read(), decoderType, mustRestore=True, dump=args.dump)\n\t\tinfer(model, FilePaths.fnInfer)\n\n\nif __name__ == '__main__':\n\tmain()"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}